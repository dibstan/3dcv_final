{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for the lecture \"Computer Vision and 3D reconstruction\"\n",
    "Winter term 2022 /23\n",
    "\n",
    "This Notbook contains the full procedure we used to train and evaluate our model. For the purpose of comprehensibility, we migrated the different basic building blocks into different auxilliary files contained in the folder \"./utils/\". For details about the implementations, please refer to these files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import zipfile\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "\n",
    "#Building blocks\n",
    "from utils.ObjectiveFunctions import *\n",
    "from utils.CreateTestTrainValSplit import splitter_downsize\n",
    "from DataSet import ImSegDataSet\n",
    "import utils.unet_utils as ut\n",
    "from utils.unet_utils import train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting started\n",
    "\n",
    "In order to run our precedure, you have to provide the necessary data set. Please download the data set from the kaggle page into the root folder of this repository:\n",
    "\n",
    "https://www.kaggle.com/datasets/bulentsiyah/semantic-drone-dataset\n",
    "\n",
    "for details about the data, please refer to this kaggle page or to\n",
    "\n",
    "https://www.tugraz.at/index.php?id=22387\n",
    "\n",
    "wher the data set has been published first.\n",
    "\n",
    "To extract the data, please run the following cell. In total, this requires roughly 12 GB of storage on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with zipfile.ZipFile(\"./archive.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./archive\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test and train our model, we need independent test and traiing data. to ensure that we do not mix up the two data set, we split the data obtained from the data set into a test set, a validation set and a traiing set. To speed up the data preprocessing during the training of the model, we save downscaled versions of the images. This may take some time. The three resulting subsets of the traiing set are stored in the directory \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instaces: 400\n",
      "instance 0:\t training set\n",
      "instance 1:\t training set\n",
      "instance 2:\t training set\n",
      "instance 3:\t training set\n",
      "instance 4:\t validation set\n",
      "instance 5:\t training set\n",
      "instance 6:\t training set\n",
      "instance 7:\t test set\n",
      "instance 8:\t training set\n",
      "instance 9:\t training set\n",
      "instance 10:\t training set\n",
      "instance 11:\t training set\n",
      "instance 12:\t training set\n",
      "instance 13:\t validation set\n",
      "instance 14:\t training set\n",
      "instance 15:\t training set\n",
      "instance 16:\t test set\n",
      "instance 17:\t training set\n",
      "instance 18:\t training set\n",
      "instance 19:\t test set\n",
      "instance 20:\t test set\n",
      "instance 21:\t training set\n",
      "instance 22:\t training set\n",
      "instance 23:\t training set\n",
      "instance 24:\t training set\n",
      "instance 25:\t training set\n",
      "instance 26:\t training set\n",
      "instance 27:\t test set\n",
      "instance 28:\t training set\n",
      "instance 29:\t training set\n",
      "instance 30:\t training set\n",
      "instance 31:\t validation set\n",
      "instance 32:\t validation set\n",
      "instance 33:\t training set\n",
      "instance 34:\t training set\n",
      "instance 35:\t training set\n",
      "instance 36:\t training set\n",
      "instance 37:\t training set\n",
      "instance 38:\t training set\n",
      "instance 39:\t training set\n",
      "instance 40:\t training set\n",
      "instance 41:\t test set\n",
      "instance 42:\t training set\n",
      "instance 43:\t training set\n",
      "instance 44:\t training set\n",
      "instance 45:\t test set\n",
      "instance 46:\t validation set\n",
      "instance 47:\t validation set\n",
      "instance 48:\t validation set\n",
      "instance 49:\t training set\n",
      "instance 50:\t training set\n",
      "instance 51:\t test set\n",
      "instance 52:\t training set\n",
      "instance 53:\t validation set\n",
      "instance 54:\t training set\n",
      "instance 55:\t training set\n",
      "instance 56:\t training set\n",
      "instance 57:\t training set\n",
      "instance 58:\t training set\n",
      "instance 59:\t test set\n",
      "instance 60:\t training set\n",
      "instance 61:\t training set\n",
      "instance 62:\t training set\n",
      "instance 63:\t training set\n",
      "instance 64:\t training set\n",
      "instance 65:\t training set\n",
      "instance 66:\t validation set\n",
      "instance 67:\t training set\n",
      "instance 68:\t training set\n",
      "instance 69:\t training set\n",
      "instance 70:\t training set\n",
      "instance 71:\t training set\n",
      "instance 72:\t training set\n",
      "instance 73:\t training set\n",
      "instance 74:\t test set\n",
      "instance 75:\t training set\n",
      "instance 76:\t training set\n",
      "instance 77:\t training set\n",
      "instance 78:\t validation set\n",
      "instance 79:\t validation set\n",
      "instance 80:\t test set\n",
      "instance 81:\t training set\n",
      "instance 82:\t validation set\n",
      "instance 83:\t test set\n",
      "instance 84:\t validation set\n",
      "instance 85:\t training set\n",
      "instance 86:\t training set\n",
      "instance 87:\t training set\n",
      "instance 88:\t training set\n",
      "instance 89:\t test set\n",
      "instance 90:\t training set\n",
      "instance 91:\t validation set\n",
      "instance 92:\t validation set\n",
      "instance 93:\t training set\n",
      "instance 94:\t training set\n",
      "instance 95:\t training set\n",
      "instance 96:\t training set\n",
      "instance 97:\t training set\n",
      "instance 98:\t training set\n",
      "instance 99:\t test set\n",
      "instance 100:\t validation set\n",
      "instance 101:\t validation set\n",
      "instance 102:\t training set\n",
      "instance 103:\t training set\n",
      "instance 104:\t training set\n",
      "instance 105:\t training set\n",
      "instance 106:\t validation set\n",
      "instance 107:\t training set\n",
      "instance 108:\t test set\n",
      "instance 109:\t training set\n",
      "instance 110:\t training set\n",
      "instance 111:\t training set\n",
      "instance 112:\t training set\n",
      "instance 113:\t training set\n",
      "instance 114:\t training set\n",
      "instance 115:\t training set\n",
      "instance 116:\t validation set\n",
      "instance 117:\t training set\n",
      "instance 118:\t test set\n",
      "instance 119:\t test set\n",
      "instance 120:\t training set\n",
      "instance 121:\t training set\n",
      "instance 122:\t training set\n",
      "instance 123:\t validation set\n",
      "instance 124:\t training set\n",
      "instance 125:\t training set\n",
      "instance 126:\t training set\n",
      "instance 127:\t training set\n",
      "instance 128:\t validation set\n",
      "instance 129:\t training set\n",
      "instance 130:\t validation set\n",
      "instance 131:\t training set\n",
      "instance 132:\t training set\n",
      "instance 133:\t training set\n",
      "instance 134:\t training set\n",
      "instance 135:\t training set\n",
      "instance 136:\t training set\n",
      "instance 137:\t training set\n",
      "instance 138:\t training set\n",
      "instance 139:\t validation set\n",
      "instance 140:\t training set\n",
      "instance 141:\t training set\n",
      "instance 142:\t training set\n",
      "instance 143:\t training set\n",
      "instance 144:\t validation set\n",
      "instance 145:\t validation set\n",
      "instance 146:\t test set\n",
      "instance 147:\t training set\n",
      "instance 148:\t test set\n",
      "instance 149:\t training set\n",
      "instance 150:\t training set\n",
      "instance 151:\t training set\n",
      "instance 152:\t training set\n",
      "instance 153:\t validation set\n",
      "instance 154:\t training set\n",
      "instance 155:\t training set\n",
      "instance 156:\t validation set\n",
      "instance 157:\t training set\n",
      "instance 158:\t training set\n",
      "instance 159:\t validation set\n",
      "instance 160:\t training set\n",
      "instance 161:\t training set\n",
      "instance 162:\t training set\n",
      "instance 163:\t training set\n",
      "instance 164:\t training set\n",
      "instance 165:\t test set\n",
      "instance 166:\t test set\n",
      "instance 167:\t training set\n",
      "instance 168:\t training set\n",
      "instance 169:\t test set\n",
      "instance 170:\t training set\n",
      "instance 171:\t test set\n",
      "instance 172:\t training set\n",
      "instance 173:\t training set\n",
      "instance 174:\t training set\n",
      "instance 175:\t training set\n",
      "instance 176:\t training set\n",
      "instance 177:\t training set\n",
      "instance 178:\t test set\n",
      "instance 179:\t training set\n",
      "instance 180:\t training set\n",
      "instance 181:\t training set\n",
      "instance 182:\t training set\n",
      "instance 183:\t training set\n",
      "instance 184:\t training set\n",
      "instance 185:\t validation set\n",
      "instance 186:\t training set\n",
      "instance 187:\t training set\n",
      "instance 188:\t training set\n",
      "instance 189:\t training set\n",
      "instance 190:\t test set\n",
      "instance 191:\t validation set\n",
      "instance 192:\t training set\n",
      "instance 193:\t training set\n",
      "instance 194:\t training set\n",
      "instance 195:\t training set\n",
      "instance 196:\t training set\n",
      "instance 197:\t validation set\n",
      "instance 198:\t training set\n",
      "instance 199:\t training set\n",
      "instance 200:\t training set\n",
      "instance 201:\t training set\n",
      "instance 202:\t training set\n",
      "instance 203:\t training set\n",
      "instance 204:\t training set\n",
      "instance 205:\t training set\n",
      "instance 206:\t training set\n",
      "instance 207:\t training set\n",
      "instance 208:\t training set\n",
      "instance 209:\t training set\n",
      "instance 210:\t validation set\n",
      "instance 211:\t training set\n",
      "instance 212:\t training set\n",
      "instance 213:\t training set\n",
      "instance 214:\t training set\n",
      "instance 215:\t test set\n",
      "instance 216:\t training set\n",
      "instance 217:\t validation set\n",
      "instance 218:\t training set\n",
      "instance 219:\t training set\n",
      "instance 220:\t test set\n",
      "instance 221:\t training set\n",
      "instance 222:\t validation set\n",
      "instance 223:\t training set\n",
      "instance 224:\t training set\n",
      "instance 225:\t training set\n",
      "instance 226:\t training set\n",
      "instance 227:\t training set\n",
      "instance 228:\t test set\n",
      "instance 229:\t training set\n",
      "instance 230:\t training set\n",
      "instance 231:\t training set\n",
      "instance 232:\t training set\n",
      "instance 233:\t training set\n",
      "instance 234:\t training set\n",
      "instance 235:\t training set\n",
      "instance 236:\t training set\n",
      "instance 237:\t validation set\n",
      "instance 238:\t training set\n",
      "instance 239:\t training set\n",
      "instance 240:\t training set\n",
      "instance 241:\t training set\n",
      "instance 242:\t training set\n",
      "instance 243:\t test set\n",
      "instance 244:\t training set\n",
      "instance 245:\t test set\n",
      "instance 246:\t training set\n",
      "instance 247:\t training set\n",
      "instance 248:\t training set\n",
      "instance 249:\t training set\n",
      "instance 250:\t training set\n",
      "instance 251:\t training set\n",
      "instance 252:\t training set\n",
      "instance 253:\t test set\n",
      "instance 254:\t training set\n",
      "instance 255:\t validation set\n",
      "instance 256:\t training set\n",
      "instance 257:\t test set\n",
      "instance 258:\t training set\n",
      "instance 259:\t training set\n",
      "instance 260:\t training set\n",
      "instance 261:\t validation set\n",
      "instance 262:\t training set\n",
      "instance 263:\t training set\n",
      "instance 264:\t training set\n",
      "instance 265:\t training set\n",
      "instance 266:\t test set\n",
      "instance 267:\t validation set\n",
      "instance 268:\t training set\n",
      "instance 269:\t training set\n",
      "instance 270:\t training set\n",
      "instance 271:\t training set\n",
      "instance 272:\t test set\n",
      "instance 273:\t test set\n",
      "instance 274:\t training set\n",
      "instance 275:\t training set\n",
      "instance 276:\t training set\n",
      "instance 277:\t training set\n",
      "instance 278:\t training set\n",
      "instance 279:\t training set\n",
      "instance 280:\t training set\n",
      "instance 281:\t training set\n",
      "instance 282:\t training set\n",
      "instance 283:\t training set\n",
      "instance 284:\t training set\n",
      "instance 285:\t validation set\n",
      "instance 286:\t training set\n",
      "instance 287:\t training set\n",
      "instance 288:\t test set\n",
      "instance 289:\t training set\n",
      "instance 290:\t training set\n",
      "instance 291:\t test set\n",
      "instance 292:\t test set\n",
      "instance 293:\t training set\n",
      "instance 294:\t training set\n",
      "instance 295:\t training set\n",
      "instance 296:\t training set\n",
      "instance 297:\t training set\n",
      "instance 298:\t training set\n",
      "instance 299:\t training set\n",
      "instance 300:\t training set\n",
      "instance 301:\t training set\n",
      "instance 302:\t training set\n",
      "instance 303:\t training set\n",
      "instance 304:\t training set\n",
      "instance 305:\t training set\n",
      "instance 306:\t training set\n",
      "instance 307:\t test set\n",
      "instance 308:\t training set\n",
      "instance 309:\t training set\n",
      "instance 310:\t training set\n",
      "instance 311:\t training set\n",
      "instance 312:\t training set\n",
      "instance 313:\t training set\n",
      "instance 314:\t training set\n",
      "instance 315:\t training set\n",
      "instance 316:\t training set\n",
      "instance 317:\t training set\n",
      "instance 318:\t validation set\n",
      "instance 319:\t training set\n",
      "instance 320:\t test set\n",
      "instance 321:\t training set\n",
      "instance 322:\t training set\n",
      "instance 323:\t training set\n",
      "instance 324:\t training set\n",
      "instance 325:\t validation set\n",
      "instance 326:\t training set\n",
      "instance 327:\t validation set\n",
      "instance 328:\t training set\n",
      "instance 329:\t validation set\n",
      "instance 330:\t training set\n",
      "instance 331:\t training set\n",
      "instance 332:\t training set\n",
      "instance 333:\t training set\n",
      "instance 334:\t training set\n",
      "instance 335:\t training set\n",
      "instance 336:\t test set\n",
      "instance 337:\t training set\n",
      "instance 338:\t training set\n",
      "instance 339:\t training set\n",
      "instance 340:\t training set\n",
      "instance 341:\t training set\n",
      "instance 342:\t training set\n",
      "instance 343:\t test set\n",
      "instance 344:\t test set\n",
      "instance 345:\t training set\n",
      "instance 346:\t training set\n",
      "instance 347:\t test set\n",
      "instance 348:\t training set\n",
      "instance 349:\t training set\n",
      "instance 350:\t training set\n",
      "instance 351:\t test set\n",
      "instance 352:\t training set\n",
      "instance 353:\t training set\n",
      "instance 354:\t training set\n",
      "instance 355:\t training set\n",
      "instance 356:\t training set\n",
      "instance 357:\t validation set\n",
      "instance 358:\t training set\n",
      "instance 359:\t training set\n",
      "instance 360:\t training set\n",
      "instance 361:\t validation set\n",
      "instance 362:\t training set\n",
      "instance 363:\t validation set\n",
      "instance 364:\t training set\n",
      "instance 365:\t training set\n",
      "instance 366:\t training set\n",
      "instance 367:\t training set\n",
      "instance 368:\t validation set\n",
      "instance 369:\t test set\n",
      "instance 370:\t training set\n",
      "instance 371:\t training set\n",
      "instance 372:\t validation set\n",
      "instance 373:\t training set\n",
      "instance 374:\t training set\n",
      "instance 375:\t training set\n",
      "instance 376:\t training set\n",
      "instance 377:\t training set\n",
      "instance 378:\t training set\n",
      "instance 379:\t training set\n",
      "instance 380:\t validation set\n",
      "instance 381:\t training set\n",
      "instance 382:\t training set\n",
      "instance 383:\t test set\n",
      "instance 384:\t training set\n",
      "instance 385:\t training set\n",
      "instance 386:\t training set\n",
      "instance 387:\t training set\n",
      "instance 388:\t test set\n",
      "instance 389:\t test set\n",
      "instance 390:\t training set\n",
      "instance 391:\t test set\n",
      "instance 392:\t training set\n",
      "instance 393:\t training set\n",
      "instance 394:\t training set\n",
      "instance 395:\t training set\n",
      "instance 396:\t training set\n",
      "instance 397:\t training set\n",
      "instance 398:\t training set\n",
      "instance 399:\t validation set\n"
     ]
    }
   ],
   "source": [
    "val_size = 50 #Size of the validation set\n",
    "test_size = 50 #Size of the test set\n",
    "scaling_factor = 7 #Factor by which the images are downscaled\n",
    "\n",
    "splitter_downsize(source_X=\"./archive/dataset/semantic_drone_dataset/original_images/\",source_Y=\"./archive/dataset/semantic_drone_dataset/label_images_semantic/\",val_size=val_size,test_size=test_size,scaling_factor=scaling_factor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training of the UNET\n",
    "\n",
    "After creating the data set, the UNet can be trained. The hyperparameters for the training are all set in the below config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the training parameters here\n",
    "config = {\n",
    "    \"lr\": 0.0003,\n",
    "    \"loss\":\"combo\",\n",
    "    \"batchSize\":10,\n",
    "    \"patchSize\":256,\n",
    "    \"nEpochs\":3,\n",
    "    \"bufferSize\":5,\n",
    "    \"bufferUpdateFreq\":1,\n",
    "    \"bufferPickSize\":3,\n",
    "    \"batchSizeDataLoaderTrain\":1,\n",
    "    \"useRotation\":False,\n",
    "    \"useMirroring\":False,\n",
    "    \"scalingFactor\":10,\n",
    "    \"useOriginal\":True,\n",
    "    \"classCountThreshold\":3,\n",
    "    \"modelParameters\":{\"in_channels\":3, \"out_channels\":24, \"sizes\":[64, 128, 256, 512]},\n",
    "    \"modelName\":\"uNet\",\n",
    "    \"optimizer\":\"Adam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible loss functions\n",
    "loss_dict = {\n",
    "    \"dice\": DiceLoss,\n",
    "    \"combo\":CriterionCombo,\n",
    "    \"focal\": FocalLoss\n",
    "}\n",
    "\n",
    "#Possible model architectures\n",
    "model_dict = {\n",
    "    \"uNet\":ut.UNet\n",
    "}\n",
    "\n",
    "#Possible optimizers\n",
    "optimizer_dict = {\n",
    "    \"Adam\":optim.Adam,\n",
    "    \"SGD\":optim.SGD\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model, the data loaders for validation and training as well as the optimizer used to adapt the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################################################\n",
      "INFO ABOUT THE DATA SET:\n",
      "\tMode of the data set:\ttrain\n",
      "\tNumber of instances:\t300\n",
      "\tImage: (C,H,W):\t\t(3,571,857)\n",
      "#########################################################################################\n",
      "\n",
      "\n",
      "#########################################################################################\n",
      "INFO ABOUT THE DATA SET:\n",
      "\tMode of the data set:\tvalidation\n",
      "\tNumber of instances:\t50\n",
      "\tImage: (C,H,W):\t\t(3,571,857)\n",
      "#########################################################################################\n",
      "\n",
      "The tag for this training run is:\n",
      "training_run_1\n"
     ]
    }
   ],
   "source": [
    "#Select the device on which the training runs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Select the objective function\n",
    "crit = loss_dict[config[\"loss\"]]\n",
    "\n",
    "#Initialize the model\n",
    "model = model_dict[config[\"modelName\"]](**config[\"modelParameters\"]).to(device)\n",
    "model.apply(ut.initialize_weights)\n",
    "\n",
    "#Initialize the objective function\n",
    "optimizer = optimizer_dict[config[\"optimizer\"]](model.parameters(), lr = config[\"lr\"])\n",
    "\n",
    "#Data set and data loader for the training set\n",
    "DS_training = ImSegDataSet(PathToDataSet=\"./data/train_set/\",mode = \"train\")\n",
    "DL_training = DataLoader(dataset=DS_training,batch_size=config[\"batchSizeDataLoaderTrain\"],shuffle=True)\n",
    "\n",
    "#Data set and data loader for the validation set\n",
    "print(\"\\n\")\n",
    "DS_validation = ImSegDataSet(PathToDataSet=\"./data/validation_set/\",mode = \"validation\")\n",
    "DL_validation = DataLoader(dataset=DS_validation,batch_size=5)\n",
    "\n",
    "#Tag to identify the training run\n",
    "tag = \"training_run_1\"\n",
    "print(f\"\\nThe tag for this training run is:\\n{tag}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model given the above hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:13<1:07:20, 13.51s/it]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = train(\n",
    "        model = model, \n",
    "        dataloader_training = DL_training, \n",
    "        dataLoader_validation = DL_validation,\n",
    "        optimizer = optimizer, \n",
    "        criterion = crit, \n",
    "        device = device, \n",
    "        buffer_size = config[\"bufferSize\"], \n",
    "        buffer_update_freq = config[\"bufferUpdateFreq\"],\n",
    "        buffer_pick_size = config[\"bufferPickSize\"],\n",
    "        n_epochs = config[\"nEpochs\"],\n",
    "        patch_size = config[\"patchSize\"],\n",
    "        batch_size = config[\"batchSize\"],\n",
    "        tag = tag,\n",
    "        rotation = config[\"useRotation\"],\n",
    "        mirroring = config[\"useMirroring\"],\n",
    "        scaling_factor = config[\"scalingFactor\"],\n",
    "        use_original = config[\"useOriginal\"],\n",
    "        threshold=config[\"classCountThreshold\"],\n",
    "        config = config\n",
    "        )\n",
    "\n",
    "except RuntimeError:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV3DR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "543859e6cb5676a4c5b97bf94eb858b1a65753f4d65ae5e1e9d924a66f3b0802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
