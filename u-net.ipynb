{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.unet_utils as ut\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.unet_utils import train\n",
    "from DataSet import ImSegDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################################################\n",
      "INFO ABOUT THE DATA SET:\n",
      "\tMode of the data set:\ttrain\n",
      "\tNumber of instances:\t300\n",
      "\tImage: (C,H,W):\t\t(3,4000,6000)\n",
      "#########################################################################################\n",
      "\n",
      "\n",
      "#########################################################################################\n",
      "INFO ABOUT THE DATA SET:\n",
      "\tMode of the data set:\tvalidation\n",
      "\tNumber of instances:\t50\n",
      "\tImage: (C,H,W):\t\t(3,4000,6000)\n",
      "#########################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m DS_validation \u001b[39m=\u001b[39m ImSegDataSet(PathToDataSet\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./data/validation_set/\u001b[39m\u001b[39m\"\u001b[39m,mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m DL_validation \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mDS_validation,batch_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m result \u001b[39m=\u001b[39m train(\n\u001b[0;32m     17\u001b[0m     model \u001b[39m=\u001b[39;49m model, \n\u001b[0;32m     18\u001b[0m     dataloader_training \u001b[39m=\u001b[39;49m DL_training, \n\u001b[0;32m     19\u001b[0m     dataLoader_validation \u001b[39m=\u001b[39;49m DL_validation,\n\u001b[0;32m     20\u001b[0m     optimizer \u001b[39m=\u001b[39;49m optimizer, \n\u001b[0;32m     21\u001b[0m     criterion \u001b[39m=\u001b[39;49m crit, \n\u001b[0;32m     22\u001b[0m     device \u001b[39m=\u001b[39;49m device, \n\u001b[0;32m     23\u001b[0m     buffer_size \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, \n\u001b[0;32m     24\u001b[0m     buffer_update_freq \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m     buffer_pick_size \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m     n_epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[0;32m     27\u001b[0m     patch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[0;32m     28\u001b[0m     tag \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtest_run_29_2023-03-20\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     29\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\swahl\\Documents\\CompVisProject\\3dcv_final\\utils\\unet_utils.py:128\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader_training, dataLoader_validation, optimizer, criterion, device, buffer_size, buffer_update_freq, buffer_pick_size, n_epochs, patch_size, tag)\u001b[0m\n\u001b[0;32m    123\u001b[0m buffer_labels \u001b[39m=\u001b[39m ImageBuffer(buffer_size\u001b[39m=\u001b[39mbuffer_size,buffer_pick_size\u001b[39m=\u001b[39mbuffer_pick_size,C \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,H \u001b[39m=\u001b[39m dataloader_training\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mheight,W \u001b[39m=\u001b[39m dataloader_training\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mwidth)\n\u001b[0;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m     \u001b[39m#Loop over all images in the training set\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (X,Y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader_training):\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m         \u001b[39m#Update the buffers\u001b[39;00m\n\u001b[0;32m    131\u001b[0m         buffer_images\u001b[39m.\u001b[39mupdate(new_image \u001b[39m=\u001b[39m X[\u001b[39m0\u001b[39m])\n\u001b[0;32m    132\u001b[0m         buffer_labels\u001b[39m.\u001b[39mupdate(new_image \u001b[39m=\u001b[39m Y[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\swahl\\Documents\\CompVisProject\\3dcv_final\\DataSet.py:76\u001b[0m, in \u001b[0;36mImSegDataSet.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39mLoad and return one instance of the data set\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m    Y:          Groundtruth labeling for instance index\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39m#Load the image\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m X \u001b[39m=\u001b[39m read_image(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfiles_X[index])\n\u001b[0;32m     77\u001b[0m Y \u001b[39m=\u001b[39m read_image(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles_Y[index])\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m X,Y\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torchvision\\io\\image.py:252\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m     _log_api_usage_once(read_image)\n\u001b[0;32m    251\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[1;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torchvision\\io\\image.py:229\u001b[0m, in \u001b[0;36mdecode_image\u001b[1;34m(input, mode)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[0;32m    228\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[1;32m--> 229\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mdecode_image(\u001b[39minput\u001b[39;49m, mode\u001b[39m.\u001b[39;49mvalue)\n\u001b[0;32m    230\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mlph4\\lib\\site-packages\\torch\\_ops.py:143\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    139\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Use the cross entropy loss, since we have more than two classes per pixel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "crit = nn.CrossEntropyLoss()\n",
    "model = ut.UNet(3, 24, [64, 128, 256, 512]).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#Data set and data loader for the training set\n",
    "DS_training = ImSegDataSet(PathToDataSet=\"./data/train_set/\",mode = \"train\")\n",
    "DL_training = DataLoader(dataset=DS_training,batch_size=1,shuffle=True)\n",
    "\n",
    "#Data set and data loader for the validation set\n",
    "print(\"\\n\")\n",
    "DS_validation = ImSegDataSet(PathToDataSet=\"./data/validation_set/\",mode = \"validation\")\n",
    "DL_validation = DataLoader(dataset=DS_validation,batch_size=5)\n",
    "\n",
    "result = train(\n",
    "    model = model, \n",
    "    dataloader_training = DL_training, \n",
    "    dataLoader_validation = DL_validation,\n",
    "    optimizer = optimizer, \n",
    "    criterion = crit, \n",
    "    device = device, \n",
    "    buffer_size = 5, \n",
    "    buffer_update_freq = 5,\n",
    "    buffer_pick_size = 3,\n",
    "    n_epochs = 5,\n",
    "    patch_size = 32,\n",
    "    tag = \"test_run_1_2023-03-20\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
